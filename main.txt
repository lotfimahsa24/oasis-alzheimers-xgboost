# =====================================================
# OASIS Cross-Sectional (from jboysen/mri-and-alzheimers)
# Predict Dementia (CDR>0)
# =====================================================
!pip -q install -U kagglehub xgboost scikit-learn matplotlib pandas numpy tqdm

import os, warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from xgboost import XGBClassifier
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, log_loss,
    classification_report, confusion_matrix, RocCurveDisplay
)
from tqdm.auto import tqdm
import kagglehub

# 1Ô∏è‚É£  Download dataset
path = kagglehub.dataset_download("jboysen/mri-and-alzheimers")
print("Downloaded to:", path)

# 2Ô∏è‚É£  Locate the OASIS CSV
csv_path = None
for root, dirs, files in os.walk(path):
    for f in files:
        if "oasis" in f.lower() and f.endswith(".csv"):
            csv_path = os.path.join(root, f)
            break
    if csv_path: break

if csv_path is None:
    raise FileNotFoundError("Could not locate oasis_cross-sectional.csv inside dataset.")
print("Found file:", csv_path)

# 3Ô∏è‚É£  Load data
df = pd.read_csv(csv_path)
df.columns = df.columns.str.strip()
print("Shape:", df.shape)
print(df.head())

# 4Ô∏è‚É£  Prepare features & target
num_cols = [c for c in ["Age","Educ","SES","MMSE","eTIV","nWBV"] if c in df.columns]
cat_cols = [c for c in ["M/F","Hand"] if c in df.columns]
df = df.dropna(subset=num_cols+cat_cols, how="all")

# Target: Dementia (CDR>0)
df["target"] = (df["CDR"].astype(float) > 0).astype(int)
print("\nClass balance:")
print(df["target"].value_counts())

# 5Ô∏è‚É£  Split data
X = df[num_cols + cat_cols]
y = df["target"].values
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3,
                                                    random_state=42, stratify=y)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5,
                                                    random_state=42, stratify=y_temp)

# 6Ô∏è‚É£  Preprocess
num_tf = Pipeline([
    ("imp", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])
cat_tf = Pipeline([
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
])
pre = ColumnTransformer([
    ("num", num_tf, num_cols),
    ("cat", cat_tf, cat_cols)
])

# 7Ô∏è‚É£  Model
model = Pipeline([
    ("pre", pre),
    ("xgb", XGBClassifier(
        n_estimators=400,
        max_depth=3,
        learning_rate=0.05,
        subsample=0.9,
        colsample_bytree=0.9,
        reg_lambda=1.0,
        objective="binary:logistic",
        eval_metric="logloss",
        tree_method="hist",
        random_state=42
    ))
])

# 8Ô∏è‚É£  Train
print("\nTraining XGBoost...")
model.fit(X_train, y_train)

# 9Ô∏è‚É£  Validation
p_valid = model.predict_proba(X_valid)[:,1]
y_pred_v = (p_valid>=0.5).astype(int)
print("\n=== VALIDATION ===")
print("LogLoss:", log_loss(y_valid, np.c_[1-p_valid, p_valid]))
print("Accuracy:", accuracy_score(y_valid, y_pred_v))
print("AUC:", roc_auc_score(y_valid, p_valid))
print("F1:", f1_score(y_valid, y_pred_v))
print("Confusion matrix:\n", confusion_matrix(y_valid, y_pred_v))

# üîü  Test
p_test = model.predict_proba(X_test)[:,1]
y_pred = (p_test>=0.5).astype(int)
loss = log_loss(y_test, np.c_[1-p_test, p_test])
acc  = accuracy_score(y_test, y_pred)
auc  = roc_auc_score(y_test, p_test)
f1b  = f1_score(y_test, y_pred)
f1m  = f1_score(y_test, y_pred, average="macro")

print(f"\n=== TEST METRICS ===")
print(f"LogLoss : {loss:.4f}")
print(f"Accuracy: {acc:.4f}")
print(f"AUC     : {auc:.4f}")
print(f"F1-bin  : {f1b:.4f} | F1-macro: {f1m:.4f}")
print("\nClassification report:\n", classification_report(y_test, y_pred, digits=4))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

# 1Ô∏è‚É£1Ô∏è‚É£  ROC curve
RocCurveDisplay.from_predictions(y_test, p_test)
plt.title("ROC Curve ‚Äì XGBoost Alzheimer‚Äôs")
plt.grid(True)
plt.show()
